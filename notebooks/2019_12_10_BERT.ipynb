{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2019-12-10 BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nov05/yelp-dataset-challenge/blob/master/notebooks/2019_12_10_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DG44CJAVgaPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# created by nov05 on 2019-12-10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnsFX7ajgiSR",
        "colab_type": "text"
      },
      "source": [
        "https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0_Qb2ybbsaN",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-dZSDOCguAu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjhYcWHQhLt3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "1fc97597-0bdf-4010-8328-fa973eb07fb3"
      },
      "source": [
        "!pip install pytorch_pretrained_bert\n",
        "# Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.12.9"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.12.9-cp36-cp36m-linux_x86_64.whl size=609187 sha256=4138dcf5288a6481404515574d9f8f66c6defc38fe5a3915d29470f4adeb71f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/fb/b3/a89169557229468c49ca64f6839418f22461f6ee0a74f342b1\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.12.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOIwGsSmheoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "import torch\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1oTHGsXhEcw",
        "colab_type": "code",
        "outputId": "970e0cfa-b3a2-4f83-dfcd-46496e67bd78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 5970920.22B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fQPJqT0eFkm",
        "colab_type": "text"
      },
      "source": [
        "# Load the \"tip\" dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6ktd4oUglYa",
        "colab_type": "code",
        "outputId": "55e579ca-2707-4d7e-e098-94b98e58150b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "# this is the \"tip\" dataset from Yelp Dataset Challenge\n",
        "# Tips written by a user on a business. Tips are shorter \n",
        "# than reviews and tend to convey quick suggestions.\n",
        "path = \"/content/drive/My Drive/data/2019-12-06 yelp/yelp_dataset/csv_out/tip.csv\"\n",
        "df_tip = pd.read_csv(path)\n",
        "print(df_tip.shape)\n",
        "df_tip.sample(3)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1223094, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>compliment_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>61774</th>\n",
              "      <td>IEa1sjfVQBIwnopfZoq6eQ</td>\n",
              "      <td>jwRBWbgTuiaQUrv-FpT8uw</td>\n",
              "      <td>Corn is awesome!</td>\n",
              "      <td>2013-07-26 16:38:42</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>828515</th>\n",
              "      <td>AILinqhWzAp8vpxlJO1eGQ</td>\n",
              "      <td>S8l7YkOZptot0KzOmz8I7g</td>\n",
              "      <td>Place is super packed</td>\n",
              "      <td>2012-07-02 03:35:04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1056996</th>\n",
              "      <td>r-0gbX6hMthYfeWY7nwGiA</td>\n",
              "      <td>hihud--QRriCYZw1zZvW4g</td>\n",
              "      <td>Love this place!! Great atmosphere, good drink...</td>\n",
              "      <td>2015-05-05 02:27:27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        user_id  ... compliment_count\n",
              "61774    IEa1sjfVQBIwnopfZoq6eQ  ...                0\n",
              "828515   AILinqhWzAp8vpxlJO1eGQ  ...                0\n",
              "1056996  r-0gbX6hMthYfeWY7nwGiA  ...                0\n",
              "\n",
              "[3 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-5x5j7yOAI2",
        "colab_type": "code",
        "outputId": "55d0e07a-f1bf-4419-e9ae-b6064df94704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "# locate the records containing \"awesome\", \"strong\" and \"great\"\n",
        "df_tmp = df_tip.dropna()[df_tip['text'].dropna().str\\\n",
        "                        #  .contains(\"^(?=.*awesome)(?=.*strong)(?=.*great).+\", \n",
        "                         .contains(\"service was awesome drinks were strong and tasty.\",\n",
        "                                   flags=re.IGNORECASE, regex=True)]\n",
        "print(df_tmp.shape)\n",
        "df_tmp"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>compliment_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>513958</th>\n",
              "      <td>aUcq6MBD9qmRBDg-x8h2gQ</td>\n",
              "      <td>_MzJncLDDFC7-0QLt1KQcg</td>\n",
              "      <td>Service was awesome drinks were strong and tas...</td>\n",
              "      <td>2016-12-31 04:25:04</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       user_id  ... compliment_count\n",
              "513958  aUcq6MBD9qmRBDg-x8h2gQ  ...                0\n",
              "\n",
              "[1 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlouSMpuiYKY",
        "colab_type": "code",
        "outputId": "83b9081d-d7b9-48be-ccb2-745f83331a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text = df_tip.loc[513958, 'text']\n",
        "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_text = tokenizer.tokenize(marked_text)\n",
        "\n",
        "# Print out the tokens.\n",
        "print (tokenized_text)\n",
        "# the BERT tokenizer was created with a WordPiece model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[CLS]', 'service', 'was', 'awesome', 'drinks', 'were', 'strong', 'and', 'ta', '##sty', '.', 'food', 'was', 'great', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSo10x2Aoo1l",
        "colab_type": "code",
        "outputId": "1a2e7199-a33a-4c4f-da22-e6e65e0771b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "# Map the token strings to their vocabulary indices.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "\n",
        "# Display the words with their indeces.\n",
        "for tup in zip(tokenized_text, indexed_tokens):\n",
        "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS]           101\n",
            "service       2,326\n",
            "was           2,001\n",
            "awesome      12,476\n",
            "drinks        8,974\n",
            "were          2,020\n",
            "strong        2,844\n",
            "and           1,998\n",
            "ta           11,937\n",
            "##sty        21,756\n",
            ".             1,012\n",
            "food          2,833\n",
            "was           2,001\n",
            "great         2,307\n",
            "[SEP]           102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O12POQG3A3IY",
        "colab_type": "code",
        "outputId": "b182bc8e-0cae-47b9-f99f-164c45b233da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "print (segments_ids)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNytCAq9a-Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([indexed_tokens])\n",
        "segments_tensors = torch.tensor([segments_ids])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2KZ-kPj2pCZ",
        "colab_type": "text"
      },
      "source": [
        "# Load BERT base model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sDYvzoaA8jx",
        "colab_type": "code",
        "outputId": "b3e97e27-e733-4f1b-eb26-e3cc2f3a0fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 407873900/407873900 [00:06<00:00, 65239138.13B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iE1MwaZBY6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict hidden states features for each layer\n",
        "with torch.no_grad():\n",
        "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FYdam8tCpkr",
        "colab_type": "code",
        "outputId": "ddd2dff4-9bd3-4832-dd7a-9d7b87a6aff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print (\"Number of layers:\", len(encoded_layers))\n",
        "layer_i = 0\n",
        "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "batch_i = 0\n",
        "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "token_i = 0\n",
        "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of layers: 12\n",
            "Number of batches: 1\n",
            "Number of tokens: 15\n",
            "Number of hidden units: 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dz_K5QLggW8Z",
        "colab_type": "code",
        "outputId": "1696a102-90a5-40cb-e841-4f77c3d81c91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# For the 5th token in our sentence, select its feature values from layer 5.\n",
        "token_i = 5\n",
        "layer_i = 5\n",
        "vec = encoded_layers[layer_i][batch_i][token_i]\n",
        "\n",
        "# Plot the values as a histogram to show their distribution.\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.hist(vec, bins=200)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAD4CAYAAAA0JjXXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 576x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFEnsgEkgndE",
        "colab_type": "code",
        "outputId": "b8ac4902-96b3-4f1f-b624-7437c84376f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# `encoded_layers` is a Python list.\n",
        "print('Type of encoded_layers: ', type(encoded_layers))\n",
        "\n",
        "# Each layer in the list is a torch tensor.\n",
        "print('Tensor shape for each layer: ', encoded_layers[0].size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Type of encoded_layers:  <class 'list'>\n",
            "Tensor shape for each layer:  torch.Size([1, 15, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMNi44XcEE-n",
        "colab_type": "text"
      },
      "source": [
        "# Token Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_H7mKI3pgs5h",
        "colab_type": "code",
        "outputId": "6597c914-b911-4e4b-f6ce-45ceab82281e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Concatenate the tensors for all layers. We use `stack` here to\n",
        "# create a new dimension in the tensor.\n",
        "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 1, 15, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnbYrF5ypUtN",
        "colab_type": "code",
        "outputId": "5de4d665-27b4-452b-8495-bacc4f654a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Remove dimension 1, the \"batches\".\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12, 15, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Css7RwSUt2Ax",
        "colab_type": "code",
        "outputId": "402f6558-8f22-4d33-f187-868a137a60e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# switch around the “layers” and “tokens” dimensions\n",
        "# Swap dimensions 0 and 1.\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "token_embeddings.size()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([15, 12, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDor-3F2x8k4",
        "colab_type": "code",
        "outputId": "f5c95527-1c8f-44c6-e47d-cc7cae62d35b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Stores the token vectors, with shape [15 x 3,072]\n",
        "token_vecs_cat = []\n",
        "\n",
        "# `token_embeddings` is a [15 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "    \n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Concatenate the vectors (that is, append them together) from the last \n",
        "    # four layers.\n",
        "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "    \n",
        "    # Use `cat_vec` to represent `token`.\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 15 x 3072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfoi_dJsyF50",
        "colab_type": "code",
        "outputId": "ca6143b6-b2e4-4535-edd9-3683ae68f46b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Stores the token vectors, with shape [15 x 768]\n",
        "token_vecs_sum = []\n",
        "\n",
        "# `token_embeddings` is a [15 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Sum the vectors from the last four layers.\n",
        "    sum_vec = torch.sum(token[-4:], dim=0)\n",
        "    \n",
        "    # Use `sum_vec` to represent `token`.\n",
        "    token_vecs_sum.append(sum_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape is: 15 x 768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht2w4Zgjyg5w",
        "colab_type": "text"
      },
      "source": [
        "# Sentence Vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jinFdjRykhF",
        "colab_type": "code",
        "outputId": "3000fec1-622c-45c8-b34c-5f4c899d1e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# `encoded_layers` has shape [12 x 1 x 15 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [15 x 768]\n",
        "token_vecs = encoded_layers[11][0]\n",
        "\n",
        "# Calculate the average of all 15 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "\n",
        "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our final sentence embedding vector of shape: torch.Size([768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmrbhAdvDrRz",
        "colab_type": "text"
      },
      "source": [
        "# Token Vector Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiBTJgxNzE7r",
        "colab_type": "code",
        "outputId": "072545ba-cbac-479b-9822-f3cca723c707",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "for i, token_str in enumerate(tokenized_text):\n",
        "    print (i, token_str)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 [CLS]\n",
            "1 service\n",
            "2 was\n",
            "3 awesome\n",
            "4 drinks\n",
            "5 were\n",
            "6 strong\n",
            "7 and\n",
            "8 ta\n",
            "9 ##sty\n",
            "10 .\n",
            "11 food\n",
            "12 was\n",
            "13 great\n",
            "14 [SEP]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fhBRWQKzUXW",
        "colab_type": "code",
        "outputId": "9f885081-4d84-4d35-a44d-91de7a733280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print('First 5 vector values for 3 adjectives.')\n",
        "print(\"awesome \", str(token_vecs_sum[3][:5]))\n",
        "print(\"strong \", str(token_vecs_sum[6][:5]))\n",
        "print(\"great \", str(token_vecs_sum[13][:5]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 5 vector values for 3 adjectives.\n",
            "great  tensor([3.2793, 0.4395, 0.4706, 3.9851, 3.3688])\n",
            "strong  tensor([-2.8577, -2.6828,  2.8643,  2.7328,  2.1268])\n",
            "awesome  tensor([-0.0675,  0.7492, -1.2852,  3.2361,  1.3994])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UiZqdR40E-_",
        "colab_type": "code",
        "outputId": "b923bb2a-cf83-4f81-9897-cb1f7b7f5418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from scipy.spatial.distance import cosine\n",
        "\n",
        "# similarity between \"awesome\" and \"great\" in this sentence\n",
        "similarity_1 = 1 - cosine(token_vecs_sum[3], token_vecs_sum[13])\n",
        "# similarity between \"awesome\" and \"strong\" in this sentence\n",
        "similarity_2 = 1 - cosine(token_vecs_sum[3], token_vecs_sum[6])\n",
        "\n",
        "print('Vector similarity for  *similar*  meanings:  %.2f' % similarity_1)\n",
        "print('Vector similarity for *different* meanings:  %.2f' % similarity_2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector similarity for  *similar*  meanings:  0.84\n",
            "Vector similarity for *different* meanings:  0.55\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig8rH5fQaepg",
        "colab_type": "text"
      },
      "source": [
        "# Sentence Vector Cosine Similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcg-2EZdadCq",
        "colab_type": "code",
        "outputId": "1ad7b5ba-5d68-4778-9a7e-9f0fbdfc7576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        }
      },
      "source": [
        "# locate the records containing \"awesome\", \"strong\" and \"great\"\n",
        "df_tmp = df_tip.dropna()[df_tip['text'].dropna().str\\\n",
        "                         .contains(\"^(?=.*awesome)(?=.*strong)(?=.*great).+\", \n",
        "                                   flags=re.IGNORECASE, regex=True)]\n",
        "print(df_tmp.shape)\n",
        "df_tmp[['text', 'compliment_count']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(11, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>compliment_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>194157</th>\n",
              "      <td>Awesome guy and a great service. I would stron...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>623316</th>\n",
              "      <td>Awesome coffee and strong and great customer s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656748</th>\n",
              "      <td>Great food, music and strong AC. There is a pa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>722313</th>\n",
              "      <td>Awesome little coffee shop! Great atmosphere, ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>733967</th>\n",
              "      <td>Service was great drinks were strong and uniqu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>834502</th>\n",
              "      <td>Awesome ambience, great sliders and strong hap...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877995</th>\n",
              "      <td>The bartender Melanie is awesome. Great drinks...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>906875</th>\n",
              "      <td>Awesome food!! Great service. Armstrongs is aw...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960644</th>\n",
              "      <td>Strong! And by strong I mean awesome although ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>985927</th>\n",
              "      <td>This awesome place has great service and excel...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1069983</th>\n",
              "      <td>We love it here, it is our go to place to eat....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text  compliment_count\n",
              "194157   Awesome guy and a great service. I would stron...                 0\n",
              "623316   Awesome coffee and strong and great customer s...                 0\n",
              "656748   Great food, music and strong AC. There is a pa...                 0\n",
              "722313   Awesome little coffee shop! Great atmosphere, ...                 0\n",
              "733967   Service was great drinks were strong and uniqu...                 0\n",
              "834502   Awesome ambience, great sliders and strong hap...                 0\n",
              "877995   The bartender Melanie is awesome. Great drinks...                 0\n",
              "906875   Awesome food!! Great service. Armstrongs is aw...                 0\n",
              "960644   Strong! And by strong I mean awesome although ...                 0\n",
              "985927   This awesome place has great service and excel...                 0\n",
              "1069983  We love it here, it is our go to place to eat....                 0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09MQCRkZcArv",
        "colab_type": "code",
        "outputId": "0f25d252-e640-40d8-c3e1-f51fbc1d350b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "# locate the records containing \"terrible\" and \"disappointing\"\n",
        "df_tmp = df_tip.dropna()[df_tip['text'].dropna().str\\\n",
        "                         .contains(\"^(?=.*terrible)(?=.*disappointing).+\", \n",
        "                                   flags=re.IGNORECASE, regex=True)]\n",
        "print(df_tmp.shape)\n",
        "df_tmp[['text', 'compliment_count']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(26, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>compliment_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>62151</th>\n",
              "      <td>Disappointing menu. No veal or lamb. Short rib...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182509</th>\n",
              "      <td>Very disappointing especially for the price! S...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207873</th>\n",
              "      <td>Free wifi.. And today 08/30/15 Lisa our server...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274184</th>\n",
              "      <td>Found the food terrible the last 2 visits.  Th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305520</th>\n",
              "      <td>Luis (friendly/laid back) = good bartender.  G...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441496</th>\n",
              "      <td>Terrible! Tried it a few times just to give a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>724297</th>\n",
              "      <td>Extremely disappointing experience.  Received ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>759825</th>\n",
              "      <td>I'm sorry but I cannot give this restaurant a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>795184</th>\n",
              "      <td>Extremely disappointing. The food was not good...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>799403</th>\n",
              "      <td>Terrible service at the restaurant it took an ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>812648</th>\n",
              "      <td>VERY DISAPPOINTING!!! We just finished our mea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879916</th>\n",
              "      <td>Food is overpriced and not that good. The serv...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>890623</th>\n",
              "      <td>Disappointing buffet today. Watermelon tastes ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>913696</th>\n",
              "      <td>I loved everything about this place! Tonight w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961452</th>\n",
              "      <td>Terrible food quality and very disorganized. V...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000605</th>\n",
              "      <td>Super disappointing... I usually agree with re...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1022816</th>\n",
              "      <td>Terrible food, terrible customer service, so d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1084560</th>\n",
              "      <td>Very bad food. Oignon soup tasteless, lots of ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1102406</th>\n",
              "      <td>Disappointing to say the least... Good service...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1106449</th>\n",
              "      <td>We both got chicken salad, terrible.  The fres...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1148485</th>\n",
              "      <td>Terrible service.  Wasn't busy for a Saturday ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1164308</th>\n",
              "      <td>Disappointing, terrible food, nothing is fresh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1168148</th>\n",
              "      <td>Terrible service and although they got my orde...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1168734</th>\n",
              "      <td>Turkey burger is terrible.... Frozen processed...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1181674</th>\n",
              "      <td>Worst margarita I've ever had. And it was $16....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1214670</th>\n",
              "      <td>I got the house spaghetti and meatballs. The s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      text  compliment_count\n",
              "62151    Disappointing menu. No veal or lamb. Short rib...                 0\n",
              "182509   Very disappointing especially for the price! S...                 0\n",
              "207873   Free wifi.. And today 08/30/15 Lisa our server...                 0\n",
              "274184   Found the food terrible the last 2 visits.  Th...                 0\n",
              "305520   Luis (friendly/laid back) = good bartender.  G...                 0\n",
              "441496   Terrible! Tried it a few times just to give a ...                 0\n",
              "724297   Extremely disappointing experience.  Received ...                 0\n",
              "759825   I'm sorry but I cannot give this restaurant a ...                 0\n",
              "795184   Extremely disappointing. The food was not good...                 0\n",
              "799403   Terrible service at the restaurant it took an ...                 0\n",
              "812648   VERY DISAPPOINTING!!! We just finished our mea...                 0\n",
              "879916   Food is overpriced and not that good. The serv...                 0\n",
              "890623   Disappointing buffet today. Watermelon tastes ...                 0\n",
              "913696   I loved everything about this place! Tonight w...                 0\n",
              "961452   Terrible food quality and very disorganized. V...                 0\n",
              "1000605  Super disappointing... I usually agree with re...                 1\n",
              "1022816  Terrible food, terrible customer service, so d...                 0\n",
              "1084560  Very bad food. Oignon soup tasteless, lots of ...                 0\n",
              "1102406  Disappointing to say the least... Good service...                 0\n",
              "1106449  We both got chicken salad, terrible.  The fres...                 0\n",
              "1148485  Terrible service.  Wasn't busy for a Saturday ...                 0\n",
              "1164308  Disappointing, terrible food, nothing is fresh...                 0\n",
              "1168148  Terrible service and although they got my orde...                 0\n",
              "1168734  Turkey burger is terrible.... Frozen processed...                 0\n",
              "1181674  Worst margarita I've ever had. And it was $16....                 0\n",
              "1214670  I got the house spaghetti and meatballs. The s...                 0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu_Bag9feWhy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d9e1f4bc-97b4-4634-bcc6-3fbfa6db92f5"
      },
      "source": [
        "%%time\n",
        "# choose two positive and two negative tip texts\n",
        "indices = [194157, 623316, 62151, 182509]\n",
        "embeddings = []\n",
        "\n",
        "for idx in indices:\n",
        "    text = df_tip.loc[idx, 'text']\n",
        "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
        "    # Tokenize our sentence with the BERT tokenizer.\n",
        "    tokenized_text = tokenizer.tokenize(marked_text)\n",
        "    # Map the token strings to their vocabulary indices.\n",
        "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    # Mark each of the 22 tokens as belonging to sentence \"1\".\n",
        "    segments_ids = [1] * len(tokenized_text)\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    segments_tensors = torch.tensor([segments_ids])\n",
        "    # Predict hidden states features for each layer\n",
        "    with torch.no_grad():\n",
        "        encoded_layers, _ = model(tokens_tensor, segments_tensors)\n",
        "    # Concatenate the tensors for all layers. We use `stack` here to\n",
        "    # create a new dimension in the tensor.\n",
        "    token_embeddings = torch.stack(encoded_layers, dim=0)\n",
        "    # `token_vecs` is a tensor with shape [15 x 768]\n",
        "    token_vecs = encoded_layers[11][0]\n",
        "    # Calculate the average of all 15 token vectors.\n",
        "    sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "    embeddings.append(sentence_embedding)\n",
        "'''\n",
        "# for 4 tips\n",
        "CPU times: user 665 ms, sys: 4.67 ms, total: 670 ms\n",
        "Wall time: 839 ms\n",
        "'''    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 665 ms, sys: 4.67 ms, total: 670 ms\n",
            "Wall time: 839 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWB8OSA_b941",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "918cb198-d53a-4adc-9972-41bd0176e7d3"
      },
      "source": [
        "for i, e in enumerate(embeddings):\n",
        "    similarity = 1 - cosine(embeddings[0], embeddings[i-3])\n",
        "    print(df_tip.loc[indices[0], 'text'])\n",
        "    print(df_tip.loc[indices[i-3], 'text'])\n",
        "    print('Sentence vector similarity: %.2f' % similarity)\n",
        "    print()\n",
        "# what can this similarity explain? ヽ(•̀ω•́ )ゝ\n",
        "# maybe just get the sentences with the highest similarity\n",
        "# e.g. search though the tips for businesses in the same area\n",
        "#      to propose similar businesses\n",
        "# this should be combined with sentiment analysis?"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Awesome guy and a great service. I would strongly recommend to anyone.\n",
            "Awesome coffee and strong and great customer service!!\n",
            "Sentence vector similarity: 0.71\n",
            "\n",
            "Awesome guy and a great service. I would strongly recommend to anyone.\n",
            "Disappointing menu. No veal or lamb. Short ribs were terrible\n",
            "Sentence vector similarity: 0.62\n",
            "\n",
            "Awesome guy and a great service. I would strongly recommend to anyone.\n",
            "Very disappointing especially for the price! Server was terrible. My food order was wrong so I had to wait for them to cook the meal I ordered while I watched my husband finish his food.  Then when my dinner finally arrived I shoveled my food down because we both couldn't wait to get out of there. Great date night.  Won't be going back.\n",
            "Sentence vector similarity: 0.67\n",
            "\n",
            "Awesome guy and a great service. I would strongly recommend to anyone.\n",
            "Awesome guy and a great service. I would strongly recommend to anyone.\n",
            "Sentence vector similarity: 1.00\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}